---
title: "Package demo"
author: "William Shih, Ricardo Simpao, Nilay Varshney, Luke Yee"
date: "3/20/2020"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here is an example of how our package functions run. For our data set, we are using a "SGEMM GPU kernel performance Data Set," which measures the running times of a matrix-matrix product, given different parameter combinations.

```{r load, message = FALSE}
library(devtools)
library(tidyverse)
library(STA141CFinal)

dat = read_csv("sgemm_product.csv")
```

```{r linear regression with bootstrap}
#We specifiy a specific column set
y = dat$`Run1 (ms)`
x = dat[,1:(ncol(dat)-4)]

#linear model objects
fit = linear_reg_bs(x = x, y = y, s = 10, r = 1000)
#fit$bootstrap_coefficient_estimates

fit2 = linear_reg_bs_par(x = x, y = y, s = 10, r = 1000)
#fit2$bootstrap_coefficient_estimates
```

# Linear Regression with blb
```{r, echo = FALSE}
linear_reg_bs2 <- function(x, y, s = 10, r = 1000) {
  n <- dim(x)[1]
  p <- dim(x)[2] + 1
  print(n)
  x1 <- cbind(Intercept = rep(1, n), x)
  sample_indices <- sample(n)
  samples <- sample(s)
  x_samples <- split(x1[sample_indices,], samples)
  y_samples <- split(y[sample_indices], samples)
  bs_coefs <- list()
  bs_s2 <- list()
  for(i in 1:s) {
    sample_coefs <- NULL
    sample_s2 <- NULL
    for (j in 1:r){
      n_sub <- length(y_samples[[i]])
      freqs <- rmultinom(1, n, rep(1, n_sub))
      subset <- data.frame(x_samples[[i]], y_samples[[i]])
      resamp = subset[rep(seq_len(nrow(subset)), freqs),]
      x_resamp <- as.matrix(resamp[,1:p])
      y_resamp <- as.matrix(resamp[,p+1])
      coefs <- solve(t(x_resamp) %*% x_resamp) %*% t(x_resamp) %*% y_resamp
      fv <- x_resamp %*% coefs
      res <- y_resamp - fv
      s2 <- sum(res^2) / (n_sub - p)
      sample_coefs <- cbind(sample_coefs, coefs)
      sample_s2 <- c(sample_s2, s2)
    }
    bs_coefs[[i]] <- sample_coefs
    bs_s2[[i]] <- sample_s2
  }
  return(list(bootstrap_coefficient_estimates = bs_coefs,
              bootstrap_s2_estimates = bs_s2))
}
```

# 95 % Confidence Interval for Variable Coefficients
```{r CI of coef}
coef_CI(fit, alpha = 0.05)

coef_CI_par(fit,alpha = 0.05)

(b1 = bench::mark(
  coef_CI(fit, alpha = 0.05),
  coef_CI_par(fit,alpha = 0.05))
)
```

Notice that `coef_CI_par` offers better memory allocation than `coef_CI`.


```{r prediction interval, eval = FALSE}
plan(multiprocess, workers = 4)
PI(fit, dat[1:3, 1:14], alpha = 0.05)
PI_par(fit, dat[1:3, 1:14], alpha = 0.05)

(b2 = bench::mark(
  PI(fit, x, alpha = 0.05),
  PI_par(fit, x, alpha = 0.05))
)
```

# 95 % Confindence Interval for Variance
```{r variance interval}
s2_CI(fit, alpha = 0.05)
s2_CI_par(fit, alpha = 0.05)

(b3 = bench::mark(
  s2_CI(fit, alpha = 0.05),
  s2_CI_par(fit, alpha = 0.05))
)
```

Notice that `s2_CI_par` offers better memory allocation than `s2_CI`.

